{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import preprocessing\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = 'Dataset/train'\n",
    "validation_dir = 'Dataset/val'\n",
    "test_dir = 'Dataset/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset_from_directory(dire, batch_size, img_size):\n",
    "    return image_dataset_from_directory(dire,shuffle=True,\n",
    "                                            batch_size=batch_size,\n",
    "                                            image_size=img_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(batch_size, img_size, base_learning_rate, initial_epochs, fine_tune_at, fine_tune_epochs):\n",
    "    train_dataset = get_dataset_from_directory(train_dir, batch_size, img_size)\n",
    "    validation_dataset = get_dataset_from_directory(validation_dir, batch_size, img_size)\n",
    "    test_dataset = get_dataset_from_directory(test_dir, batch_size, img_size)\n",
    "\n",
    "    val_batches = tf.data.experimental.cardinality(validation_dataset)\n",
    "\n",
    "    AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "    train_dataset = train_dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "    validation_dataset = validation_dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "    test_dataset = test_dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "    # DATA AUGMENTATION\n",
    "    data_augmentation = tf.keras.Sequential([\n",
    "        tf.keras.layers.experimental.preprocessing.RandomFlip('horizontal'),\n",
    "        tf.keras.layers.experimental.preprocessing.RandomRotation(0.2),\n",
    "    ])\n",
    "\n",
    "    preprocess_input = tf.keras.applications.densenet.preprocess_input\n",
    "    IMG_SHAPE = img_size + (3,)\n",
    "    base_model = tf.keras.applications.DenseNet201(input_shape=IMG_SHAPE,\n",
    "                                                   include_top=False,\n",
    "                                                   weights='imagenet')\n",
    "\n",
    "    image_batch, label_batch = next(iter(train_dataset))\n",
    "    feature_batch = base_model(image_batch)\n",
    "\n",
    "    base_model.trainable = False\n",
    "\n",
    "    global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
    "    feature_batch_average = global_average_layer(feature_batch)\n",
    "\n",
    "    prediction_layer = tf.keras.layers.Dense(1)\n",
    "    prediction_batch = prediction_layer(feature_batch_average)\n",
    "\n",
    "    inputs = tf.keras.Input(shape=(160, 160, 3))\n",
    "    x = data_augmentation(inputs)\n",
    "    x = preprocess_input(x)\n",
    "    x = base_model(x, training=False)\n",
    "    x = global_average_layer(x)\n",
    "    x = tf.keras.layers.Dropout(0.2)(x)\n",
    "    outputs = prediction_layer(x)\n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(lr=base_learning_rate),\n",
    "                  loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    loss0, accuracy0 = model.evaluate(validation_dataset)\n",
    "    print(\"initial loss: {:.2f}\".format(loss0))\n",
    "    print(\"initial accuracy: {:.2f}\".format(accuracy0))\n",
    "\n",
    "    history = model.fit(train_dataset,\n",
    "                        epochs=initial_epochs,\n",
    "                        validation_data=validation_dataset,\n",
    "                        verbose=0)\n",
    "\n",
    "    base_model.trainable = True\n",
    "\n",
    "    for layer in base_model.layers[:fine_tune_at]:\n",
    "        layer.trainable = False\n",
    "\n",
    "    model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                  optimizer=tf.keras.optimizers.RMSprop(lr=base_learning_rate / 10),\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    total_epochs = initial_epochs + fine_tune_epochs\n",
    "\n",
    "    history_fine = model.fit(train_dataset,\n",
    "                             epochs=total_epochs,\n",
    "                             initial_epoch=history.epoch[-1],\n",
    "                             validation_data=validation_dataset,\n",
    "                             verbose=0)\n",
    "\n",
    "    loss, accuracy = model.evaluate(test_dataset)\n",
    "    print('Test accuracy :', accuracy)\n",
    "    return accuracy, history, history_fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyper parameters: batch size: 16 learning_rate: 0.0001 initial_epochs: 10, fine_tune_epochs: 10, fine_tune_at: 630\n",
      "Found 38391 files belonging to 2 classes.\n",
      "Found 8226 files belonging to 2 classes.\n",
      "Found 8227 files belonging to 2 classes.\n",
      "515/515 [==============================] - 29s 56ms/step - loss: 0.7726 - accuracy: 0.4408\n",
      "initial loss: 0.77\n",
      "initial accuracy: 0.44\n",
      "515/515 [==============================] - 29s 57ms/step - loss: 0.2518 - accuracy: 0.9369\n",
      "Test accuracy : 0.9369150400161743\n",
      "Accuracy = 0.9369150400161743\n",
      "Hyper parameters: batch size: 16 learning_rate: 0.0001 initial_epochs: 10, fine_tune_epochs: 10, fine_tune_at: 640\n",
      "Found 38391 files belonging to 2 classes.\n",
      "Found 8226 files belonging to 2 classes.\n",
      "Found 8227 files belonging to 2 classes.\n",
      "515/515 [==============================] - 28s 53ms/step - loss: 0.8374 - accuracy: 0.3519\n",
      "initial loss: 0.84\n",
      "initial accuracy: 0.35\n",
      "515/515 [==============================] - 29s 56ms/step - loss: 0.2172 - accuracy: 0.9367\n",
      "Test accuracy : 0.9366719126701355\n",
      "Accuracy = 0.9366719126701355\n",
      "Hyper parameters: batch size: 16 learning_rate: 0.0001 initial_epochs: 10, fine_tune_epochs: 10, fine_tune_at: 650\n",
      "Found 38391 files belonging to 2 classes.\n",
      "Found 8226 files belonging to 2 classes.\n",
      "Found 8227 files belonging to 2 classes.\n",
      "515/515 [==============================] - 29s 56ms/step - loss: 0.9309 - accuracy: 0.4640\n",
      "initial loss: 0.93\n",
      "initial accuracy: 0.46\n",
      "515/515 [==============================] - 29s 56ms/step - loss: 0.2143 - accuracy: 0.9324\n",
      "Test accuracy : 0.932417631149292\n",
      "Accuracy = 0.932417631149292\n",
      "Hyper parameters: batch size: 16 learning_rate: 0.0001 initial_epochs: 10, fine_tune_epochs: 10, fine_tune_at: 660\n",
      "Found 38391 files belonging to 2 classes.\n",
      "Found 8226 files belonging to 2 classes.\n",
      "Found 8227 files belonging to 2 classes.\n",
      "515/515 [==============================] - 29s 56ms/step - loss: 0.7610 - accuracy: 0.5035\n",
      "initial loss: 0.76\n",
      "initial accuracy: 0.50\n",
      "515/515 [==============================] - 29s 57ms/step - loss: 0.2413 - accuracy: 0.9359\n",
      "Test accuracy : 0.9359426498413086\n",
      "Accuracy = 0.9359426498413086\n",
      "Hyper parameters: batch size: 16 learning_rate: 0.0001 initial_epochs: 10, fine_tune_epochs: 10, fine_tune_at: 670\n",
      "Found 38391 files belonging to 2 classes.\n",
      "Found 8226 files belonging to 2 classes.\n",
      "Found 8227 files belonging to 2 classes.\n",
      "515/515 [==============================] - 29s 56ms/step - loss: 0.8781 - accuracy: 0.4722\n",
      "initial loss: 0.88\n",
      "initial accuracy: 0.47\n",
      "515/515 [==============================] - 29s 56ms/step - loss: 0.2202 - accuracy: 0.9357\n",
      "Test accuracy : 0.9356995224952698\n",
      "Accuracy = 0.9356995224952698\n",
      "Hyper parameters: batch size: 16 learning_rate: 0.0001 initial_epochs: 10, fine_tune_epochs: 20, fine_tune_at: 630\n",
      "Found 38391 files belonging to 2 classes.\n",
      "Found 8226 files belonging to 2 classes.\n",
      "Found 8227 files belonging to 2 classes.\n",
      "515/515 [==============================] - 29s 56ms/step - loss: 0.7516 - accuracy: 0.4916\n",
      "initial loss: 0.75\n",
      "initial accuracy: 0.49\n",
      "515/515 [==============================] - 29s 57ms/step - loss: 0.3247 - accuracy: 0.9329\n",
      "Test accuracy : 0.9329038262367249\n",
      "Accuracy = 0.9329038262367249\n",
      "Hyper parameters: batch size: 16 learning_rate: 0.0001 initial_epochs: 10, fine_tune_epochs: 20, fine_tune_at: 640\n",
      "Found 38391 files belonging to 2 classes.\n",
      "Found 8226 files belonging to 2 classes.\n",
      "Found 8227 files belonging to 2 classes.\n",
      "515/515 [==============================] - 29s 56ms/step - loss: 0.7007 - accuracy: 0.5139\n",
      "initial loss: 0.70\n",
      "initial accuracy: 0.51\n",
      "515/515 [==============================] - 29s 56ms/step - loss: 0.2961 - accuracy: 0.9350\n",
      "Test accuracy : 0.9349702000617981\n",
      "Accuracy = 0.9349702000617981\n",
      "Hyper parameters: batch size: 16 learning_rate: 0.0001 initial_epochs: 10, fine_tune_epochs: 20, fine_tune_at: 650\n",
      "Found 38391 files belonging to 2 classes.\n",
      "Found 8226 files belonging to 2 classes.\n",
      "Found 8227 files belonging to 2 classes.\n",
      "515/515 [==============================] - 29s 57ms/step - loss: 0.8017 - accuracy: 0.4850\n",
      "initial loss: 0.80\n",
      "initial accuracy: 0.49\n",
      "515/515 [==============================] - 29s 56ms/step - loss: 0.3221 - accuracy: 0.9376\n",
      "Test accuracy : 0.937644362449646\n",
      "Accuracy = 0.937644362449646\n",
      "Hyper parameters: batch size: 16 learning_rate: 0.0001 initial_epochs: 10, fine_tune_epochs: 20, fine_tune_at: 660\n",
      "Found 38391 files belonging to 2 classes.\n",
      "Found 8226 files belonging to 2 classes.\n",
      "Found 8227 files belonging to 2 classes.\n",
      "515/515 [==============================] - 29s 57ms/step - loss: 0.6727 - accuracy: 0.6228\n",
      "initial loss: 0.67\n",
      "initial accuracy: 0.62\n",
      "515/515 [==============================] - 29s 56ms/step - loss: 0.2642 - accuracy: 0.9386\n",
      "Test accuracy : 0.9386167526245117\n",
      "Accuracy = 0.9386167526245117\n",
      "Hyper parameters: batch size: 16 learning_rate: 0.0001 initial_epochs: 10, fine_tune_epochs: 20, fine_tune_at: 670\n",
      "Found 38391 files belonging to 2 classes.\n",
      "Found 8226 files belonging to 2 classes.\n",
      "Found 8227 files belonging to 2 classes.\n",
      "515/515 [==============================] - 28s 55ms/step - loss: 0.5975 - accuracy: 0.6059\n",
      "initial loss: 0.60\n",
      "initial accuracy: 0.61\n",
      "515/515 [==============================] - 29s 56ms/step - loss: 0.2416 - accuracy: 0.9342\n",
      "Test accuracy : 0.9342409372329712\n",
      "Accuracy = 0.9342409372329712\n",
      "Hyper parameters: batch size: 16 learning_rate: 0.0001 initial_epochs: 10, fine_tune_epochs: 30, fine_tune_at: 630\n",
      "Found 38391 files belonging to 2 classes.\n",
      "Found 8226 files belonging to 2 classes.\n",
      "Found 8227 files belonging to 2 classes.\n",
      "515/515 [==============================] - 28s 55ms/step - loss: 0.7570 - accuracy: 0.4912\n",
      "initial loss: 0.76\n",
      "initial accuracy: 0.49\n",
      "515/515 [==============================] - 29s 57ms/step - loss: 0.4840 - accuracy: 0.9312\n",
      "Test accuracy : 0.9312021136283875\n",
      "Accuracy = 0.9312021136283875\n",
      "Hyper parameters: batch size: 16 learning_rate: 0.0001 initial_epochs: 10, fine_tune_epochs: 30, fine_tune_at: 640\n",
      "Found 38391 files belonging to 2 classes.\n",
      "Found 8226 files belonging to 2 classes.\n",
      "Found 8227 files belonging to 2 classes.\n",
      "515/515 [==============================] - 30s 57ms/step - loss: 0.7830 - accuracy: 0.4170\n",
      "initial loss: 0.78\n",
      "initial accuracy: 0.42\n",
      "515/515 [==============================] - 29s 57ms/step - loss: 0.5259 - accuracy: 0.9269\n",
      "Test accuracy : 0.926947832107544\n",
      "Accuracy = 0.926947832107544\n",
      "Hyper parameters: batch size: 16 learning_rate: 0.0001 initial_epochs: 10, fine_tune_epochs: 30, fine_tune_at: 650\n",
      "Found 38391 files belonging to 2 classes.\n",
      "Found 8226 files belonging to 2 classes.\n",
      "Found 8227 files belonging to 2 classes.\n",
      "515/515 [==============================] - 29s 57ms/step - loss: 0.7292 - accuracy: 0.5266\n",
      "initial loss: 0.73\n",
      "initial accuracy: 0.53\n",
      "515/515 [==============================] - 29s 56ms/step - loss: 0.5118 - accuracy: 0.9240\n",
      "Test accuracy : 0.924030601978302\n",
      "Accuracy = 0.924030601978302\n",
      "Hyper parameters: batch size: 16 learning_rate: 0.0001 initial_epochs: 10, fine_tune_epochs: 30, fine_tune_at: 660\n",
      "Found 38391 files belonging to 2 classes.\n",
      "Found 8226 files belonging to 2 classes.\n",
      "Found 8227 files belonging to 2 classes.\n",
      "515/515 [==============================] - 28s 55ms/step - loss: 0.7912 - accuracy: 0.5050\n",
      "initial loss: 0.79\n",
      "initial accuracy: 0.50\n",
      "515/515 [==============================] - 29s 56ms/step - loss: 0.4901 - accuracy: 0.9340\n",
      "Test accuracy : 0.9339978098869324\n",
      "Accuracy = 0.9339978098869324\n",
      "Hyper parameters: batch size: 16 learning_rate: 0.0001 initial_epochs: 10, fine_tune_epochs: 30, fine_tune_at: 670\n",
      "Found 38391 files belonging to 2 classes.\n",
      "Found 8226 files belonging to 2 classes.\n",
      "Found 8227 files belonging to 2 classes.\n",
      "515/515 [==============================] - 29s 56ms/step - loss: 0.7124 - accuracy: 0.5688\n",
      "initial loss: 0.71\n",
      "initial accuracy: 0.57\n",
      "515/515 [==============================] - 29s 57ms/step - loss: 0.4148 - accuracy: 0.9254\n",
      "Test accuracy : 0.9253677129745483\n",
      "Accuracy = 0.9253677129745483\n",
      "Hyper parameters: batch size: 16 learning_rate: 0.0001 initial_epochs: 20, fine_tune_epochs: 10, fine_tune_at: 630\n",
      "Found 38391 files belonging to 2 classes.\n",
      "Found 8226 files belonging to 2 classes.\n",
      "Found 8227 files belonging to 2 classes.\n",
      "515/515 [==============================] - 29s 56ms/step - loss: 0.9393 - accuracy: 0.3534\n",
      "initial loss: 0.94\n",
      "initial accuracy: 0.35\n",
      "515/515 [==============================] - 29s 56ms/step - loss: 0.2618 - accuracy: 0.9362\n",
      "Test accuracy : 0.9361857175827026\n",
      "Accuracy = 0.9361857175827026\n",
      "Hyper parameters: batch size: 16 learning_rate: 0.0001 initial_epochs: 20, fine_tune_epochs: 10, fine_tune_at: 640\n",
      "Found 38391 files belonging to 2 classes.\n",
      "Found 8226 files belonging to 2 classes.\n",
      "Found 8227 files belonging to 2 classes.\n",
      "515/515 [==============================] - 29s 57ms/step - loss: 0.7537 - accuracy: 0.5089\n",
      "initial loss: 0.75\n",
      "initial accuracy: 0.51\n",
      "515/515 [==============================] - 29s 56ms/step - loss: 0.2384 - accuracy: 0.9383\n",
      "Test accuracy : 0.9382520914077759\n",
      "Accuracy = 0.9382520914077759\n",
      "Hyper parameters: batch size: 16 learning_rate: 0.0001 initial_epochs: 20, fine_tune_epochs: 10, fine_tune_at: 650\n",
      "Found 38391 files belonging to 2 classes.\n",
      "Found 8226 files belonging to 2 classes.\n",
      "Found 8227 files belonging to 2 classes.\n",
      "515/515 [==============================] - 29s 57ms/step - loss: 0.6094 - accuracy: 0.6984\n",
      "initial loss: 0.61\n",
      "initial accuracy: 0.70\n",
      "515/515 [==============================] - 29s 56ms/step - loss: 0.2374 - accuracy: 0.9368\n",
      "Test accuracy : 0.9367935061454773\n",
      "Accuracy = 0.9367935061454773\n",
      "Hyper parameters: batch size: 16 learning_rate: 0.0001 initial_epochs: 20, fine_tune_epochs: 10, fine_tune_at: 660\n",
      "Found 38391 files belonging to 2 classes.\n",
      "Found 8226 files belonging to 2 classes.\n",
      "Found 8227 files belonging to 2 classes.\n",
      "515/515 [==============================] - 28s 55ms/step - loss: 0.6811 - accuracy: 0.5524\n",
      "initial loss: 0.68\n",
      "initial accuracy: 0.55\n",
      "515/515 [==============================] - 29s 56ms/step - loss: 0.2242 - accuracy: 0.9373\n",
      "Test accuracy : 0.9372797012329102\n",
      "Accuracy = 0.9372797012329102\n",
      "Hyper parameters: batch size: 16 learning_rate: 0.0001 initial_epochs: 20, fine_tune_epochs: 10, fine_tune_at: 670\n",
      "Found 38391 files belonging to 2 classes.\n",
      "Found 8226 files belonging to 2 classes.\n",
      "Found 8227 files belonging to 2 classes.\n",
      "515/515 [==============================] - 28s 54ms/step - loss: 0.7078 - accuracy: 0.5257\n",
      "initial loss: 0.71\n",
      "initial accuracy: 0.53\n",
      "515/515 [==============================] - 29s 56ms/step - loss: 0.2618 - accuracy: 0.9311\n",
      "Test accuracy : 0.9310805797576904\n",
      "Accuracy = 0.9310805797576904\n",
      "Hyper parameters: batch size: 16 learning_rate: 0.0001 initial_epochs: 20, fine_tune_epochs: 20, fine_tune_at: 630\n",
      "Found 38391 files belonging to 2 classes.\n",
      "Found 8226 files belonging to 2 classes.\n",
      "Found 8227 files belonging to 2 classes.\n",
      "515/515 [==============================] - 29s 56ms/step - loss: 0.8528 - accuracy: 0.4750\n",
      "initial loss: 0.85\n",
      "initial accuracy: 0.47\n",
      "515/515 [==============================] - 29s 56ms/step - loss: 0.4618 - accuracy: 0.9312\n",
      "Test accuracy : 0.9312021136283875\n",
      "Accuracy = 0.9312021136283875\n",
      "Hyper parameters: batch size: 16 learning_rate: 0.0001 initial_epochs: 20, fine_tune_epochs: 20, fine_tune_at: 640\n",
      "Found 38391 files belonging to 2 classes.\n",
      "Found 8226 files belonging to 2 classes.\n",
      "Found 8227 files belonging to 2 classes.\n",
      "515/515 [==============================] - 28s 55ms/step - loss: 0.9600 - accuracy: 0.5351\n",
      "initial loss: 0.96\n",
      "initial accuracy: 0.54\n",
      "515/515 [==============================] - 29s 57ms/step - loss: 0.3284 - accuracy: 0.9373\n",
      "Test accuracy : 0.9372797012329102\n",
      "Accuracy = 0.9372797012329102\n",
      "Hyper parameters: batch size: 16 learning_rate: 0.0001 initial_epochs: 20, fine_tune_epochs: 20, fine_tune_at: 650\n",
      "Found 38391 files belonging to 2 classes.\n",
      "Found 8226 files belonging to 2 classes.\n",
      "Found 8227 files belonging to 2 classes.\n",
      "515/515 [==============================] - 29s 57ms/step - loss: 0.8378 - accuracy: 0.3257\n",
      "initial loss: 0.84\n",
      "initial accuracy: 0.33\n",
      "515/515 [==============================] - 29s 56ms/step - loss: 0.3908 - accuracy: 0.9350\n",
      "Test accuracy : 0.9349702000617981\n",
      "Accuracy = 0.9349702000617981\n",
      "Hyper parameters: batch size: 16 learning_rate: 0.0001 initial_epochs: 20, fine_tune_epochs: 20, fine_tune_at: 660\n",
      "Found 38391 files belonging to 2 classes.\n",
      "Found 8226 files belonging to 2 classes.\n",
      "Found 8227 files belonging to 2 classes.\n",
      "515/515 [==============================] - 29s 56ms/step - loss: 0.7569 - accuracy: 0.4899\n",
      "initial loss: 0.76\n",
      "initial accuracy: 0.49\n",
      "515/515 [==============================] - 29s 57ms/step - loss: 0.3213 - accuracy: 0.9357\n",
      "Test accuracy : 0.9356995224952698\n",
      "Accuracy = 0.9356995224952698\n",
      "Hyper parameters: batch size: 16 learning_rate: 0.0001 initial_epochs: 20, fine_tune_epochs: 20, fine_tune_at: 670\n",
      "Found 38391 files belonging to 2 classes.\n",
      "Found 8226 files belonging to 2 classes.\n",
      "Found 8227 files belonging to 2 classes.\n",
      "515/515 [==============================] - 29s 55ms/step - loss: 0.7744 - accuracy: 0.4519\n",
      "initial loss: 0.77\n",
      "initial accuracy: 0.45\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-0574295f7fb5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m                     print(\"Hyper parameters: batch size: {} learning_rate: {} initial_epochs: {}, fine_tune_epochs: {}, fine_tune_at: {}\"\n\u001b[1;32m     14\u001b[0m                           .format(batch_sz, lr, in_epochs, ft_epochs, ft_at))\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_sz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIMG_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mft_at\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mft_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Accuracy = {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-df80fd9577b8>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(batch_size, img_size, base_learning_rate, initial_epochs, fine_tune_at, fine_tune_epochs)\u001b[0m\n\u001b[1;32m     54\u001b[0m                         \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m                         \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m                         verbose=0)\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mbase_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python37/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python37/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python37/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python37/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python37/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python37/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/anaconda3/envs/python37/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size = [16, 32, 64, 128]\n",
    "IMG_SIZE = (160, 160)\n",
    "base_learning_rate = [0.0001]\n",
    "initial_epochs = [10, 20, 30]\n",
    "fine_tune_epochs = [10, 20, 30]\n",
    "fine_tune_at = [630, 640, 650, 660, 670]\n",
    "\n",
    "for batch_sz in batch_size:\n",
    "    for lr in base_learning_rate:\n",
    "        for in_epochs in initial_epochs:\n",
    "            for ft_epochs in fine_tune_epochs:\n",
    "                for ft_at in fine_tune_at:\n",
    "                    print(\"Hyper parameters: batch size: {} learning_rate: {} initial_epochs: {}, fine_tune_epochs: {}, fine_tune_at: {}\"\n",
    "                          .format(batch_sz, lr, in_epochs, ft_epochs, ft_at))\n",
    "                    acc, _, _ = train_model(batch_sz, IMG_SIZE, lr, in_epochs, ft_at, ft_epochs)\n",
    "                    print(\"Accuracy = {}\".format(acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
